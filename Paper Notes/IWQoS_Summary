  2012
AIST:Insights into Queuing and Loss on Highly Multiplexed Links
在显式的或延迟驱动的拥塞控制中，一个共同的目标是在网络路径的瓶颈链路上保持高
吞吐量而没有长队列和大的损失。拥塞控制协议通过在稳定状态下平稳传输来努力实现
这一目标。发现适当的稳态传输速率本身就是一项具有挑战性的任务，通常会带来额外
的排队和损失。为了深入了解实际协议可实现的排队和丢失的稳态状态，本文提出了一
种AIST（具有理想平滑传输的异步到达）模型，该模型抽象出与发现路径容量相关的暂
时排队和损失，并重新将数据包流重新分布在瓶颈链路上。在AIST中，流异步到达，但
在稳定状态下以相同的恒定速率传输它们的数据包。对于具有过度调配缓冲区的链路，
我们针对分组到达间隔时间的不同平滑分布的排队理论分析和仿真认为，在AIST下的目
标利用率为1的排队在N的平方根的数量级上，其中N是流的数量。对于小缓冲区，我们对
AIST的模拟显示无论流量的数量如何，都可以提供有界损失率。

Adaptive Dynamic Priority Scheduling for Virtual Desktop Infrastructures
虚拟桌面基础架构（VDI）在云计算中越来越受欢迎，它允许公司将其办公环境部署在虚
拟化环境中，而不是依靠物理台式机。将许多用户整合到VDI环境中可显着降低IT管理费
用并实现诸如“随时随地”使用的新​​功能。但是，广泛采用的障碍包括虚拟化I / O性能下
降，CPU调度干扰问题以及共享缓存争用。在本文中，我们提出了一种新的软实时调度算
法，该算法采用灵活的优先级指定（通过效用函数）和自动调度程序类别检测（通过管理
程序监视用户行为）来提供更高质量的用户体验。我们已经在Xen虚拟化平台内部实施了
我们的调度程序，并且证明了将大量虚拟机集中在一起的开销可以从现有调度程序的66％
降低到系统中的2％以下。我们评估在VDI设置中使用较小调度时间段的好处和开销，并显
示每个调度程序调用的平均开销时间与现有SEDF和Credit调度程序的顺序相同

Preventing TCP Incast Throughput Collapse at the Initiation, Continuation, and Termination
随着数据中心技术的进步，Incast应用程序越来越受欢迎。发现TCP incast可能会受到
吞吐量崩溃问题的困扰，这是TCP瓶颈缓冲区不堪重负并导致数据包丢失的TCP重传超时的
结果。这对云计算应用程序的服务质量至关重要。虽然以前的一些文献提出了解决方案，但
我们仍然看到问题没有完全解决。在本文中，我们研究了TCP incast流性能不佳的三个根
本原因，并提出了三种解决方案，一个用于TCP连接的开始，中间和结束。这三种解决方案
是：对TCP流量进行准入控制，使流量人口不会超过网络的容量;基于时间戳的重发来检测重
发分组的丢失;并重申FIN数据包以保持TCP连接处于活动状态，直到会话终止被确认。这些
解决方案的编排可防止吞吐量崩溃。这些解决方案的主要思想是确保所有正在进行的TCP incast流
可以保持自我时钟，从而消除了重新启动超时进行恢复的需要。我们评估这些解决方案并发现
它们在防止TCP incast流的重新传输超时方面效果良好，因此也可以防止吞吐量崩溃。

2013
A Datacenter Network Tale from a Server's Perspective
许多数据中心应用的可扩展性在很大程度上取决于网络基础设施。一些研究从网络设备的角
度讨论了网络流量特征，即收集和分析来自路由器，交换机或其他网络聚合点的流量数据。
但是，关于服务器如何直接生成流量的知之甚少。在本文中，我们进行了一项实证研究，以
服务器为中心来描述数据中心流量。我们在两年的时间跨度内分析来自超过30,000台服务器
的数据，这些服务器位于50多个生产数据中心内。我们的评估包括流量统计以及网络资源，基
于短期快照和收集指标的长期演进。特别是，我们描述了跨服务器的传入和传出流量的时间和
空间特征，以数据包以及每秒字节数为特征。我们的分析为数据中心网络建模和工作负荷模型
校准提供了基准。

On Interference-aware Provisioning for Cloud-based Big Data Processing
基于云计算的大数据分析方面的最新进展为弹性和成本有效的探索大型数据集提供了便利的手段。
在这种趋势之后，亚马逊，谷歌和IBM等行业领先企业在其云平台上部署了各种大数据系统，旨在
占领全球的巨大市场。虽然这些云系统极大地促进了大数据分析的实施，但其实际适用性仍然很不
明朗。在本文中，我们迈出了第一步，以更好地理解云平台上的大数据系统。使用典型的MapReduce
框架作为案例研究，我们发现其基于流水线的设计将计算 - 密集型操作（如映射/减少）以及I / O密
集型操作（如混洗）混合在一起。这种计算密集型和I / O密集型操作将严重影响对方的性能，并且极
大地降低系统效率，特别是对于低端虚拟机（VM）。更糟糕的是，我们的测量还表明，超过90％的任
务寿命都在这种干扰的阴影之下。这不可避免地降低了基于云计算的大数据处理的适用性，并且难以
预测整体性能。为了解决这个问题，我们重新建模了基于云计算的大数据系统中的资源调配问题，并
提出了一种干扰感知解决方案，可以巧妙地将MapReduce作业分配给不同的VM。我们的评估结果显
示，我们的新模型可以准确预测不同配置的作业完成时间，并显着改善新一代数据处理服务的用户体验。

Adaptive Data Transmission in the Cloud
数据中心为广泛的服务提供资源，如网络搜索，电子邮件，网站等，每个服务都有不同的延迟要求。例
如，网络搜索应该很快地迎合用户的要求，而数据备份对完成时间没有特殊要求。不同的应用程序也引
入具有非常不同属性（例如大小和持续时间）的流。数据中心的默认传输方式即TCP，平均处理流量，迫
使平等分配瓶颈的网络带宽。这种公平性导致时间敏感型应用的结果不佳。更好的解决方案是为时间敏感
的应用程序分配更多的带宽。但是，采用最新技术的方法都需要对数据中心网络设备进行叉车更换。在某
些情况下，还需要对端系统堆栈和应用程序进行重大更改。在本文中，我们认为对TCP的简单修改有助于
更好地满足数据中心中对延迟敏感的应用程序的要求。不需要修改终端系统，应用程序或网络设备。我们
使用真实数据中心流量的测量来激励我们的自适应TCP（ATCP）设计。我们通过分析推导出在我们对TCP
建议的修改中使用的参数。最后，我们在NS2中使用大量模拟来展示ATCP的好处。

2014
Analysing Convergence of Quantized Congestion Notification in Data Center Ethernet
将以太网作为统一数据中心架构来同时处理局域网（LAN），存储区域网络（SAN）和高性能计算（HPC）的
流量已经引起了人们的高度关注。拥塞管理是填补传统以太网和统一数据中心架构之间性能差距的一项重要
增强。目前，量化拥塞通知（QCN）已被批准为标准拥塞管理机制。然而，很多工作指出，QCN存在不同流量
之间的不公平问题。在本文中，我们发现QCN可以达到公平，但是公平的收敛时间相当长。因此，我们构建了
一个收敛时间模型来研究QCN慢收敛过程的原因。该模型表明，如果RPs具有相同的速率增长概率或者速率增
加步长在稳定状态下变大，则QCN的收敛时间可以减少。我们通过与NetFPGA平台上的实验数据进行比较来验
证我们模型的精确性。结果表明，它很好地表征了QCN公平的收敛时间。基于该模型，分析了QCN参数，网络
参数和QCN变量对收敛时间的影响。最后，通过分析的启发，我们提出了一种称为QCN-T的机制，它用单个修
改的定时器替换源中的字节计数器和定时器，以减少QCN的收敛时间

2015
Enhancing TCP Incast Congestion Control Over Large-scale Datacenter Networks
数据中心网络中的多对一流量模式引入了传输控制协议（TCP）的巨型拥塞问题，并给云服务提供商带来
了前所未有的压力。 为了解决沉重的Incast，我们提出了面向接收机的数据中心TCP（RDTCP）。 该
建议的动机是处理巨大的Incast流量时的振荡队列大小以及拥塞控制中接收器的巨大潜力。 最后，RDTCP采
用开环和闭环拥塞控制。 我们对其设计问题进行系统讨论并实施原型来检查其性能。 评估结果表明，平
均队列长度下降47.5％，TCP上越来越重的Incast的第99百分位延迟平均减少51.2％，TCP Incast拥
塞控制（ICTCP）平均减少43.6％和11.7％。

Identifying Frequent Flows in Large Datasets through Probabilistic Bloom Filters
在许多网络应用中，精确的流量测量对于带QoS要求的带宽管理以及检测诸如DoS（拒绝服务）攻击等安全威胁
至关重要。在这种情况下，通常将流量建模为流量集合，这些流量是基于某些功能（如IP地址对）确定的。一个
主要问题是确定那些占总流量很大比例的“重击者”流量，例如至少为链路容量的0.1％。然而，这一目标面临的
挑战是为每个流量保留一个单独的计数器太慢，成本高且不可扩展。在本文中，我们描述了一种称为概率布隆过
滤器（PBF）的新型数据结构，它将古典布隆过滤器扩展到概率方向，从而可以有效识别重击者。我们分析这个数
据结构的性能，折衷和容量。我们的研究还调查了如何校准这个数据结构的参数。我们还开发了PBF的基本形式的
两个扩展，以实现更灵活的应用需求。我们使用网络查询服务器和骨干路由器上收集的真实网络跟踪来测试PBF的
性能，并证明此方法可以准确地跟踪所有对象的频率，包括网站和流量，以便可以识别重击者具有恒定的时间计算
复杂度和低内存开销

2016
Dynamic Flow Scheduling for Power-Efficient Data Center Networks
已经提出节能的数据中心网络（DCN）以使用OpenFlow节省DCN的功率。在这些DCN中，OpenFlow控制器自适应
地打开和关闭链路和OpenFlow交换机，以形成满足流量需求的最小功率子网。随着子网的变化，流量会动态调度
到由有源交换机和链路组成的路由。但是，现有的流量调度方案可能会导致不希望的结果：（1）功率低效：由于
活动路由上的流量分配不均衡，可能会激活额外的交换机和链路以迎合拥挤路由上的突发流量激增;（2）服务质
量（QoS）波动：由于流入处理能力有限，交换机无法及时安装/删除/更新流表项以正确调度流量。在本文中，我
们提出AggreFlow，这是一种动态流量调度方案，通过两种技术实现DCN中的功率效率和改进的QoS：流量集路由
和延迟重路由。流量集路由实现负载平衡，并通过以粗粒度流设置方式路由流量来减少交换机上的入口安装数量。延
迟重路由在相当长的时间内维护负载平衡并分散重路由操作，减少了交换机进入安装/删除/更新的突发性。我们建立
了一个基于NS3的胖树网络仿真平台来评估AggreFlow的性能。仿真结果表明，与baseline方案相比，AggreFlow降
低了约18％的功耗，实现了负载平衡和改进的QoS（即低丢包率，并将流量调度的处理条目数量减少了98％）

Certificate-Aware Encrypted Traffic Classification Using Second-Order Markov Chain
随着网络应用的繁荣，流量分类在网络管理和恶意攻击检测中起着至关重要的作用。广泛使用的加密传输协议（例
如安全套接字层/传输层安全性（SSL / TLS）协议）导致传统的基于有效载荷的分类方法的失败。现有的加密流
量分类方法的精确度较低。在本文中，我们提出了一种基于二阶马尔可夫链的认证加密流量分类方法。我们首先探
讨现有方法为什么表现不佳的原因，并且提出一个新的观察：SSL / TLS会话中的证书数据包长度会导致应用程序
歧视。为了增加应用指纹的多样性，我们开发了一个新的模型，将证书包长度聚类结合到二阶齐次马尔可夫链中。广
泛的评估结果表明，与分类准确性相比，所提出的方法比现有技术方法平均提高了30％。

2017
Congestion Control in Converged Ethernet with Heterogeneous and Time-Varying Delays
拥塞控制是增强以太网作为传统LAN，SAN和高性能计算网络统一结构的新趋势中不可或缺的机制。融合以太网（CE）
网络的拥塞管理框架已由IEEE 802.1Q工作组标准化，QCN被推荐为标准草案中的拥塞控制方案。 QCN是启发式设
计用于1 / 10Gbps以太网而不考虑延迟的影响。最近的工作发现QCN将遇到反馈延迟的稳定性问题，而且随着以太
网扩展到40 / 100Gbps并且延迟变得异构和时变，这些问题将更加严重。这项工作旨在减轻延迟对CE中拥塞控制
方案的负面影响。特别地，考虑到延迟是异构和时变的，我们使用标准拥塞管理框架为融合以太网建立模型。该模型
提供了一个新的拥塞检测器来估计在延迟影响下的实际拥塞状态，并将异构和时变特征视为干扰。利用新的拥塞检测
器并通过滑模控制方法容忍干扰，我们设计了延迟容忍滑模（DSM）拥塞控制方案。大量的仿真表明，当以太网的速
率范围从1Gbps到100Gbps时，DSM的性能优于其他拥塞控制方案，并且延迟异构且时变。

Skipping Congestion-links for Coflow Scheduling
大数据系统中数据传输的持续时间占完成时间的很大一部分。为了减少数据传输的时间，最近提出了一些coflow级
的流量调度机制。它们中的大多数将数据中心网络抽象为理想的无阻塞大交换机，其瓶颈位于终端主机的出口或入
口端口，而不是网络中。因此，他们主要关注如何在不考虑网内拥塞的情况下将终端主机的端口容量分配给作业。但
是，由于网络超额预订和负载不均衡，数据中心网络中经常会出现链路拥塞。当链路拥塞发生时，瓶颈位置将从终端
主机的端口移动到网络链路。在本文中，我们设计并实现了SkipL，一种拥塞感知的coflow调度器，可以检测拥塞并
在终端主机调度coflow，从而有效地减少coflow完成时间。另外，为了能够在云环境中轻松部署，SkipL不需要控
制流量路由。 SkipL原型系统在Linux中实现。在一个真实的小型试验台上进行的实验结果以及在流量级仿真器中进
行的仿真表明，与每流公平共享调度方法和Varys相比，SkipL减少了平均Coflow完成时间（CCT）。

A Cost-efficient Scheme with Decoupling Host-side Flow Scheduling from Switches in DCNs 
云数据中心使用有限的网络资源来托管复杂多样的应用程序，这需要我们将上层应用程序视为黑盒子，并为延迟敏感的
短流提供低延迟。许多优秀的性能方案需要初步获得流量信息（流量大小，截止时间或流量分布）或修改硬件或软件，这
在实践中导致使用困难和效率低下。为了解决这个难题，我们提出SPQ，一种信息不可知且易于部署的流量调度方案，可
为延迟敏感的短流量提供接近最佳的流量完成时间（FCT），并有效处理长尾分布。 SPQ将主机端流量调度从交换端流量
调度中分离出来，以实现接近最小服务（LAS）调度规则的广泛实际场景。通过这种方式，SPQ可以在终端主机上实现接近
最优的调度顺序。同时，我们利用两种新的反馈调整机制来缓解长期流量对短期流量的影响。我们的模拟显示SPQ实现了卓
越的性能和广泛的实际场景。与DCTCP，L2DCT和PIAS相比，SPQ在三种工作负载下具有明显的优势，例如，它将短流量的
平均FCT分别降低了56％，55％和8％，并将第99百分位FCT降低了高达67％，69％和24％。而SPQ短流量的平均FCT与数
据挖掘工作负载下的理想信息感知方案之间仅有0-1.1％的差距。

Delay Updating in Software-Defined Datacenter Networks
软件定义数据中心网络（SDDC）由于各种网络更新事件而不断变化。应该将每个更新事件涉及到的一组流迁移到可行路径而
没有拥塞。为了处理单个更新事件，先前的方法查找并执行迁移序列，以便将初始业务分配转换为最终业务分配。但是，在处
理多个更新事件的队列时，总是会出现队头阻塞问题，并且会大大降低网络更新的效率。为了解决这个问题，我们采用了延
迟更新的思想，它调度其他排队事件而不是阻塞的头部事件，旨在打破阻塞状态并为其他事件提供更新机会。我们将此问题
作为优化问题制定，并提出部分延迟更新（PDU）策略。 PDU根据其到达顺序处理排队的更新事件以保持公平。此外，它更
倾向于延迟那些阻塞的流量，缺乏足够的带宽资源，而不是头部事件中的所有流量。评估结果表明，我们的延迟更新策略实现
了更新事件平均完成时间的60％至80％与FIFO调度策略相比，有四种流量大小。

Queueing in the Mist: Buffering and Scheduling with Limited Knowledge
使用有界缓冲区调度和管理队列是计算机网络中最基本的问题。传统上，通常假设每个数据包的所有属性在抵达后立即知道。
但是，随着流量越来越异质复杂，这种假设在很多情况下都是无效的。特别是，在各种情况下，只有在数据包经过一些初始处
理之后，关于数据包特征的信息才可用。在这项工作中，我们研究管理知识有限的队列问题。我们首先在这些设置中显示任何
算法的竞争比率的下限。接下来，我们使用从这些边界获得的洞察力来确定适合该问题的几种算法概念，并使用这些准则设计
具体的算法框架。我们分析了我们提出的算法的性能，并进一步展示了它如何在各种设置中实现，这些设置根据未知信息的类
型和性质而不同。我们通过模拟研究进一步验证了我们的结果和算法方法，该方法在有限的知识面前提供了有关我们的算法设
计原则的进一步见解。

QoS Evaluation of Prioritized Data Plane Service Employing Queueing Model
软件定义网络（SDN）正在成为控制平面与数据平面分离的新范例。 SDN体系结构能够将基础设施混乱中的网络元素抽象为
服务资源。利用标准化的开放式应用程序接口（API），可以大大简化应用程序和网络服务的部署。在公开的文献中，已经做
了很多努力来评估数据平面的转发性能。杰克逊模型经常被用来描述这种体系结构的特征。此外，网络流量经常表现出自相似
性，得到了普遍认可。未考虑流量自相似性的分析模型可能会导致意想不到的结果。为此，本文提出了一种分析模型来评估具
有自相似输入流量的SDN数据平面的服务质量（QoS）。在数据平面使用优先服务来减少不匹配的数据包的逗留时间。这是因
为通过控制平面传输的数据包对严格的时延限制更敏感。模型的QoS可以通过分解方法进行评估。广泛的实验结果表明，我们
的模型具有很高的准确性和适用性。
